# Lecture 2: Where does the error come from?

## Bias and Variance of Estimator

Error 有兩種來源：

- bias
- variance

分析 error 的來源，可以挑選適當的方法改善 model。

以進化前的寶可夢為輸入，以進化後的真實 CP 值為輸出，真實的函數記為 $\hat f$（上帝視角才知道）

從訓練數據，我們找到 $f^\*$（$\hat f$ 的估計）

![](https://i.imgur.com/Q8eohUL.png)

用表格來看

| | 簡單模型 | 複雜模型 |
|:--:|:--:|:--:|
| variance | 小 | 大 |
| bias | 大 | 小 | 

- 簡單模型更少受 training data 影響。
- 複雜模型會盡力去擬合 training data 的變化。

Bias 即 $d(\bar f, \hat f)$

簡單模型的 model space 較小，可能根本沒有包含到 target。

- 在 underfitting 的情況下，error 大部分來自 bias。
- 在 overfitting 的情況下，error 大部分來自 variance。

---

- 如果 model 連 training data 都 fit 不好，那就是 underfitting
- 如果 model 可以 fit training data，但 testing error 大，那就是 overfitting

---

- 在 bias 大的情況下，需要重新設計 model，例如增加更多 features，或著讓 model 更複雜
- 在 variance 大的情況下，需要更多資料，或者 regularization。More data 很有效，但卻不一定可行，regularization 希望曲線平滑，但可能會損害 bias，造成 model space 無法包含 target $\hat f$。

## Model Selection

在選擇模型時，要考慮 2 種 error 的折衷，使 total error 最小。

不應這樣做：

![](https://i.imgur.com/QZZrg8C.png)

因為這樣做，在 public testing error 的表現不能完全的反應在 private testing error。

### Cross Validation

![](https://i.imgur.com/NiYfKs9.png)

將 training set 分成 training set 和 validation set，在 training set 上訓練 model 1-3，選擇在 validation set 上 error 最小的 model。

如果嫌 training set 中 data 太少的話，可以在確定 model 後在全部 training set 上再訓練一遍該 model。

這樣做，在 public testing set 上的 error 才會代表在 private testing set 上的 error。

不能用 public testing set 去調整 model！

### $N$-fold Cross Validation

![](https://i.imgur.com/L93md2I.png)

將 training set 分成 $N$ 折，每次只有一折作為 validation set，其它折作為 training set，在各 model 中選擇 $N$ 次訓練得到的 $N$ 個 validation error 均值最小的 model。
